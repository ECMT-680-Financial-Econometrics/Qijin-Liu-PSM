{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the data\n",
    "data_in = \"ipumsi_00036.parquet\"\n",
    "path = \"E:/680_temp/Daily_temp\"\n",
    "\n",
    "# read the data\n",
    "ddf = dd.read_parquet(f\"{path}\\\\{data_in}\")\n",
    "\n",
    "# rename the columns and assign to a new Dask DataFrame\n",
    "ddf = ddf.rename(columns={'country': 'cntry', 'migrate5': 'MGRATE5', 'migratep': 'mgratep'})\n",
    "\n",
    "# create a new variable\n",
    "ddf = ddf.assign(migrate=None)\n",
    "\n",
    "# dealing with the migration variable for Costa Rica\n",
    "# if country is Costa Rica and migration status is provincial (20) or national (30), set migration to 1\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 188) & (ddf['MGRATE5'].isin([20, 30])), 1))\n",
    "\n",
    "# if country is Costa Rica and MGRATE5 is 10, 11, or 12, set migration to 0\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 188) & (ddf['MGRATE5'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# deal with the migration variable for the Dominican Republic\n",
    "# if country is the Dominican Republic and migration status is provincial (20) or national (30), set migration to 1\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 214) & (ddf['MGRATE5'].isin([20, 30])), 1))\n",
    "\n",
    "# if country is the Dominican Republic and MGRATE5 is 10, 11, or 12, set migration to 0\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 214) & (ddf['MGRATE5'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Deal with the migration variable for El Salvador\n",
    "\n",
    "# Set migrate to 1 if country is El Salvador and mgratep shows migration on either Province level(20) or Country level(30)\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 222) & (ddf['mgratep'].isin([20, 30])), 1))\n",
    "\n",
    "# Set migrate to missing if country is El Salvador and mgratep is 0, 98, or 99\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 222) & (ddf['mgratep'].isin([0, 98, 99])), None))\n",
    "\n",
    "# Set migrate to 0 if country is El Salvador and mgratep is 10, 11, or 12\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 222) & (ddf['mgratep'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Deal with the migration variable for Haiti\n",
    "\n",
    "# Set migrate to 1 if country is Haiti and MGRATE5 shows migration on either Province level(20) or Country level(30)\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 332) & (ddf['MGRATE5'].isin([20, 30])), 1))\n",
    "\n",
    "# No need to modify migrate variable if country is Haiti and MGRATE5 is 0, 98, or 99\n",
    "# This step is actually unnecessary in Python, as we have already initialized all values to None\n",
    "\n",
    "# Set migrate to 0 if country is Haiti and MGRATE5 is 10, 11, or 12\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 332) & (ddf['MGRATE5'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Deal with the migration variable for Jamaica\n",
    "\n",
    "# Set migrate to 1 if country is Jamaica and mgratep shows migration on either Parish level(20) or Country level(30)\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 388) & (ddf['mgratep'].isin([20, 30])), 1))\n",
    "\n",
    "# No need to modify migrate variable if country is Jamaica and mgratep is 0, 98, or 99\n",
    "# This step is actually unnecessary in Python, as we have already initialized all values to None\n",
    "\n",
    "# Set migrate to 0 if country is Jamaica and mgratep is 10, 11, or 12\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 388) & (ddf['mgratep'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Deal with the migration variable for Mexico\n",
    "\n",
    "# Set migrate to 1 if country is Mexico and MGRATE5 shows migration on either State level(20) or Country level(30)\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 484) & (ddf['MGRATE5'].isin([20, 30])), 1))\n",
    "\n",
    "# No need to modify migrate variable if country is Mexico and MGRATE5 is 0, 98, or 99\n",
    "# This step is actually unnecessary in Python, as we have already initialized all values to None\n",
    "\n",
    "# Set migrate to 0 if country is Mexico and MGRATE5 is 10, 11, or 12\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 484) & (ddf['MGRATE5'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Deal with the migration variable for Nicaragua\n",
    "\n",
    "\n",
    "# Set migrate to 1 if country is Nicaragua and MGRATE5 shows migration on either Department level(20) or Country level(30)\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 558) & (ddf['MGRATE5'].isin([20, 30])), 1))\n",
    "\n",
    "# Set migrate to missing if country is Nicaragua and MGRATE5 is 0, 98, or 99\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 558) & (ddf['MGRATE5'].isin([0, 98, 99])), None))\n",
    "\n",
    "# Set migrate to 0 if country is Nicaragua and MGRATE5 is 10, 11, or 12\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 558) & (ddf['MGRATE5'].isin([10, 11, 12])), 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Handling the migrate variable for Panama\n",
    "\n",
    "# Set migrate to 1 if country is Panama and mgratep shows migration on either province or country level\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 591) & (ddf['mgratep'].isin([20, 30])), 1))\n",
    "\n",
    "# Set migrate to NaN if country is Panama and mgratep indicates missing or unknown migration status\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 591) & (ddf['mgratep'].isin([0, 98, 99])), np.nan))\n",
    "\n",
    "# Set migrate to 0 if country is Panama and mgratep indicates no significant migration\n",
    "ddf = ddf.assign(migrate=ddf['migrate'].where((ddf['cntry'] == 591) & (ddf['mgratep'].isin([10, 11, 12])), 0))\n",
    "\n",
    "# Dropping records where migrate is missing\n",
    "ddf = ddf.dropna(subset=['migrate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Generating the waveline variable\n",
    "\n",
    "\n",
    "# Costa Rica\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 188) & (ddf['year'] == 2011), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 188) & (ddf['year'] == 2000), 0))\n",
    "\n",
    "# Dominican Republic\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 214) & (ddf['year'] == 2010), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 214) & (ddf['year'] == 2002), 0))\n",
    "\n",
    "# El Salvador\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 222) & (ddf['year'] == 2007), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 222) & (ddf['year'] == 1992), 0))\n",
    "\n",
    "# Haiti\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 332) & (ddf['year'] == 2003), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 332) & (ddf['year'] == 1982), 0))\n",
    "\n",
    "# Jamaica\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 388) & (ddf['year'] == 2001), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 388) & (ddf['year'] == 1991), 0))\n",
    "\n",
    "# Mexico\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 484) & (ddf['year'] == 2010), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 484) & (ddf['year'] == 2000), 0))\n",
    "\n",
    "# Nicaragua\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 558) & (ddf['year'] == 2005), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 558) & (ddf['year'] == 1995), 0))\n",
    "\n",
    "# Panama\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 591) & (ddf['year'] == 2010), 1))\n",
    "ddf = ddf.assign(wave=ddf['wave'].where((ddf['cntry'] == 591) & (ddf['year'] == 2000), 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `add`.\n\nOriginal error is below:\n------------------------\nTypeError(\"unsupported operand type(s) for +: 'int' and 'Categorical'\")\n\nTraceback:\n---------\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\dataframe\\core.py\", line 6487, in elemwise\n    meta = partial_by_order(*parts, function=op, other=other)\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\utils.py\", line 1327, in partial_by_order\n    return function(*args2, **kwargs)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\common.py\", line 81, in new_method\n    return method(self, other)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\arraylike.py\", line 190, in __radd__\n    return self._arith_method(other, roperator.radd)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\series.py\", line 6112, in _arith_method\n    return base.IndexOpsMixin._arith_method(self, other, op)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\base.py\", line 1348, in _arith_method\n    result = ops.arithmetic_op(lvalues, rvalues, op)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 224, in arithmetic_op\n    res_values = op(left, right)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\roperator.py\", line 11, in radd\n    return right + left\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\dataframe\\utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36melemwise\u001b[1;34m(op, meta, out, transform_divisions, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6486\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6487\u001b[1;33m             \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial_by_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\utils.py\u001b[0m in \u001b[0;36mpartial_by_order\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0margs2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__radd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_method_SERIES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1347\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# because numexpr will fail on it, see GH#31457\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\pandas\\core\\roperator.py\u001b[0m in \u001b[0;36mradd\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mradd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'Categorical'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19008/2318335033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Costa Rica\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mddf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_dist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cntry'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m188\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'migcr2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m188000\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'migcr2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mddf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_dist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cntry'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m188\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'migrate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'geolev1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1927\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_binary_operator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0melemwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0melemwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36melemwise\u001b[1;34m(op, meta, out, transform_divisions, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6485\u001b[0m         ]\n\u001b[0;32m   6486\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6487\u001b[1;33m             \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial_by_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6489\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dd_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivisions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PYthon\\lib\\site-packages\\dask\\dataframe\\utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" in `{funcname}`\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Metadata inference failed in `add`.\n\nOriginal error is below:\n------------------------\nTypeError(\"unsupported operand type(s) for +: 'int' and 'Categorical'\")\n\nTraceback:\n---------\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\dataframe\\core.py\", line 6487, in elemwise\n    meta = partial_by_order(*parts, function=op, other=other)\n  File \"d:\\PYthon\\lib\\site-packages\\dask\\utils.py\", line 1327, in partial_by_order\n    return function(*args2, **kwargs)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\common.py\", line 81, in new_method\n    return method(self, other)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\arraylike.py\", line 190, in __radd__\n    return self._arith_method(other, roperator.radd)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\series.py\", line 6112, in _arith_method\n    return base.IndexOpsMixin._arith_method(self, other, op)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\base.py\", line 1348, in _arith_method\n    result = ops.arithmetic_op(lvalues, rvalues, op)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 224, in arithmetic_op\n    res_values = op(left, right)\n  File \"d:\\PYthon\\lib\\site-packages\\pandas\\core\\roperator.py\", line 11, in radd\n    return right + left\n"
     ]
    }
   ],
   "source": [
    "# Generating the pre_dist variable\n",
    "\n",
    "# Initialize pre_dist variable with missing values\n",
    "ddf['pre_dist'] = np.nan\n",
    "\n",
    "# Costa Rica\n",
    "ddf = ddf.assign(pre_dist=ddf['pre_dist'].where((ddf['cntry'] == 188) & (ddf['migcr2'] != 9), 188000 + ddf['migcr2']))\n",
    "ddf = ddf.assign(pre_dist=ddf['pre_dist'].where((ddf['cntry'] == 188) & (ddf['migrate'] == 0), ddf['geolev1']))\n",
    "\n",
    "# Dominican Republic\n",
    "ddf = ddf.assign(twodigit=ddf['migdo'] // 100)\n",
    "ddf = ddf.assign(pre_dist=ddf['pre_dist'].where((ddf['cntry'] == 214) & (ddf['twodigit'] <= 50), 214000 + ddf['twodigit']))\n",
    "ddf = ddf.assign(pre_dist=ddf['pre_dist'].where((ddf['cntry'] == 214) & (ddf['migrate'] == 0), ddf['geolev1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El Salvador\n",
    "df.loc[(df['cntry'] == 222) & (df['migsv'] <= 14), 'pre_dist'] = 222000 + df['migsv']\n",
    "df.loc[(df['cntry'] == 222) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Haiti\n",
    "df.loc[(df['cntry'] == 332) & (df['might2'] // 10 <= 10), 'pre_dist'] = 332000 + df['might2'] // 10\n",
    "df.loc[(df['cntry'] == 332) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Jamaica\n",
    "df.loc[(df['cntry'] == 388) & (df['migjm'] <= 14), 'pre_dist'] = 388000 + df['migjm']\n",
    "df.loc[(df['cntry'] == 388) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Mexico\n",
    "df.loc[(df['cntry'] == 484) & (df['migmx2'] <= 32), 'pre_dist'] = 484000 + df['migmx2']\n",
    "df.loc[(df['cntry'] == 484) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Nicaragua\n",
    "df.loc[(df['cntry'] == 558) & (df['migni'] <= 97), 'pre_dist'] = 558000 + df['migni']\n",
    "df.loc[(df['cntry'] == 558) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Panama\n",
    "df.loc[(df['cntry'] == 591) & (df['migpa'] // 100 <= 10), 'pre_dist'] = 591000 + df['migpa'] // 100\n",
    "df.loc[(df['cntry'] == 591) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing with the DataFrame 'df' from the previous step\n",
    "\n",
    "# El Salvador\n",
    "df.loc[(df['cntry'] == 222) & (df['migsv'] <= 14), 'pre_dist'] = 222000 + df['migsv']\n",
    "df.loc[(df['cntry'] == 222) & (df['migrate'] == 0), 'pre_dist'] = df['geolev1']\n",
    "\n",
    "# Haiti\n",
    "df.loc[(df['cntry'] == 332) & (df['might2'] // 10 <= 10), 'pre_dist'] = 332000 + (df['might2'] // 10)\n",
    "\n",
    "# Jamaica\n",
    "df.loc[(df['cntry'] == 388) & (df['migjm'] <= 14), 'pre_dist'] = 388000 + df['migjm']\n",
    "\n",
    "# Mexico\n",
    "df.loc[(df['cntry'] == 484) & (df['migmx2'] <= 32), 'pre_dist'] = 484000 + df['migmx2']\n",
    "\n",
    "# Nicaragua\n",
    "df.loc[(df['cntry'] == 558) & (df['migni'] <= 97), 'pre_dist'] = 558000 + df['migni']\n",
    "\n",
    "# Panama\n",
    "df.loc[(df['cntry'] == 591) & ((df['migpa'] // 100) <= 10), 'pre_dist'] = 591000 + (df['migpa'] // 100)\n",
    "\n",
    "# Dropping rows based on specific 'pre_dist' values\n",
    "drop_conditions = df['pre_dist'].isin([np.nan, 558097, 558090, 332010, 214012, 214020, 214028, 214029, 214030, 214031, 214032, 214050])\n",
    "df = df[~drop_conditions]\n",
    "\n",
    "# Dropping specified columns\n",
    "df.drop(['sample', 'serial', 'ownershipd', 'pernum', 'related', 'resident'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame and it already includes an 'age' column\n",
    "\n",
    "# Drop rows where individuals are younger than 15 or older than 65\n",
    "df = df[(df['age'] >= 15) & (df['age'] <= 65)]\n",
    "\n",
    "# Initialize cohort variables\n",
    "df['aff_cohort_15_25'] = 0\n",
    "df['aff_cohort_26_35'] = 0\n",
    "df['aff_cohort_36_45'] = 0\n",
    "df['aff_cohort_46_55'] = 0\n",
    "df['aff_cohort_56_65'] = 0\n",
    "\n",
    "# Populate cohort variables based on age\n",
    "df.loc[(df['age'] >= 15) & (df['age'] <= 25), 'aff_cohort_15_25'] = 1\n",
    "df.loc[(df['age'] >= 26) & (df['age'] <= 35), 'aff_cohort_26_35'] = 1\n",
    "df.loc[(df['age'] >= 36) & (df['age'] <= 45), 'aff_cohort_36_45'] = 1\n",
    "df.loc[(df['age'] >= 46) & (df['age'] <= 55), 'aff_cohort_46_55'] = 1\n",
    "df.loc[(df['age'] >= 56) & (df['age'] <= 65), 'aff_cohort_56_65'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df_main is your main dataset\n",
    "\n",
    "# Load 5-year historical climate data for wave 0 and wave 1\n",
    "df_rain_wave0 = pd.read_csv('cruts_5_rain_aerpp_wave0.csv')  # Adjust path as necessary\n",
    "df_rain_wave1 = pd.read_csv('cruts_5_rain_aerpp_wave1.csv')  # Adjust path as necessary\n",
    "\n",
    "# Rename the district identifier column to match that of the main dataset\n",
    "df_rain_wave0.rename(columns={'GEOLEV1': 'pre_dist'}, inplace=True)\n",
    "df_rain_wave1.rename(columns={'GEOLEV1': 'pre_dist'}, inplace=True)\n",
    "\n",
    "# Separate the main dataset into two based on wave\n",
    "df_wave0 = df_main[df_main['wave'] == 0]\n",
    "df_wave1 = df_main[df_main['wave'] == 1]\n",
    "\n",
    "# Merge the climate data with the main dataset based on pre_dist\n",
    "merged_wave0 = df_wave0.merge(df_rain_wave0, on='pre_dist', how='inner')\n",
    "merged_wave1 = df_wave1.merge(df_rain_wave1, on='pre_dist', how='inner')\n",
    "\n",
    "# Append the results to get a single dataset\n",
    "df_final = pd.concat([merged_wave0, merged_wave1])\n",
    "\n",
    "# Optionally, save the intermediate and final datasets\n",
    "df_final.to_csv('final_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_stata('pause_3_t.dta')  # Adjust the file path as necessary\n",
    "\n",
    "# Drop irrelevant variables\n",
    "df.drop(columns=['migcr2', 'migdo', 'migsv', 'might2', 'migjm', 'migmx2', 'migni', 'migpa', 'twodigit', '_merge', 'relate', 'MGRATE5', 'mgratep', 'country', 'ownership', 'electric', 'watsup', 'sewage', 'emp*'], inplace=True)\n",
    "\n",
    "# Save the dataset\n",
    "df.to_stata('pause_3_t_cleaned.dta', write_index=False)\n",
    "\n",
    "# Clean micro-control variables\n",
    "df['sex'].replace({2: 0, 9: np.nan}, inplace=True)  # Recode sex: 2 (female) to 0, and 9 (missing info) to NaN\n",
    "df['yrschool'].replace({91: 3, 92: 8, 93: 8, 94: 11, 95: 3, 98: np.nan, 99: np.nan}, inplace=True)  # Clean yrschool\n",
    "df['urban'].replace({1: 0, 2: 1, 9: np.nan}, inplace=True)  # Recode urban: 1 (rural) to 0, 2 (urban) to 1, and 9 (missing info) to NaN\n",
    "\n",
    "# Drop rows with missing values in sex or yrschool\n",
    "df.dropna(subset=['sex', 'yrschool'], inplace=True)\n",
    "\n",
    "# Create a binary variable for primary education\n",
    "df['primary_edu'] = (df['yrschool'] >= 6).astype(int)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_stata('pause_3_t_cleaned.dta', write_index=False)\n",
    "# Define province capitals for each country\n",
    "costa_rica_capitals = [188001001, 188002001, 188003001, 188004001, 188005002, 188006001, 188007002]\n",
    "dominican_republic_capitals = [101, 201, 301, 401, 501, 601, 701, 801, 901, 1001, 1101, 1201, 1301, 1401, 1501, 1601, 1701, 1801, 1901, 2001, 2101, 2201, 2301, 2401, 2501, 2601, 2701, 2801, 2901, 3001, 3101, 3201]\n",
    "el_salvador_capitals = [222001001, 222002001, 222003001, 222004004, 222007002, 222008001, 222013006, 222006001, 222010001]\n",
    "haiti_capitals = [332006005, 332006009, 332007004, 332003001, 332003006, 332009001, 332006001, 332006003, 332007002, 332007001]\n",
    "\n",
    "# Replace capital values for each country\n",
    "df.loc[(df['cntry'] == 188) & (df['geo2_cr'].isin(costa_rica_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 188) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 188) & (df['geo2_cr'] == 188001001), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 188) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "df.loc[(df['cntry'] == 214) & (df['geo2_dox'].isin(dominican_republic_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 214) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 214) & (df['geo2_dox'] == 3201), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 214) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "df.loc[(df['cntry'] == 222) & (df['geo2_sv'].isin(el_salvador_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 222) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 222) & (df['geo2_sv'] == 222006001), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 222) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "df.loc[(df['cntry'] == 332) & (df['geo2_ht'].isin(haiti_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 332) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 332) & (df['geo2_ht'] == 332006001), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 332) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "# Define province capitals for Mexico\n",
    "mexico_capitals = [484001001, 484002002, 484015067, 484004002, 484007100, 484008018, 484005030, 484006002, 484010005, 484011015, 484012029, 484013048, 484014039, 484015100, 484016051, 484017007, 484019039, 484032053, 484031050, 484020067, 484029032, 484021114, 484028038, 484022014, 484024028, 484025006, 484026030]\n",
    "\n",
    "# Replace capital values for Mexico\n",
    "df.loc[(df['cntry'] == 484) & (df['geo2_mx'].isin(mexico_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 484) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 484) & (df['geolev1'] == 484009), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 484) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "# Define province capitals for Nicaragua\n",
    "nicaragua_capitals = [5010, 7510, 3045, 6510, 3570, 7015, 1035, 3540, 2005, 5525, 6010, 545, 8040, 8520, 9055]\n",
    "\n",
    "# Replace capital values for Nicaragua\n",
    "df.loc[(df['cntry'] == 558) & (df['geo2_nix'].isin(nicaragua_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 558) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 558) & (df['geo2_nix'] == 5525), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 558) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n",
    "\n",
    "# Define province capitals for Panama\n",
    "panama_capitals = [591004001, 591004002, 591002001, 591003001, 591006001, 591008001, 591008003]\n",
    "\n",
    "# Replace capital values for Panama\n",
    "df.loc[(df['cntry'] == 591) & (df['geo2_pa'].isin(panama_capitals)), 'capital'] = 1\n",
    "df.loc[(df['cntry'] == 591) & (df['capital'].isna()), 'capital'] = 0\n",
    "df.loc[(df['cntry'] == 591) & (df['geo2_pa'] == 591008001), 'capital_cntry'] = 1\n",
    "df.loc[(df['cntry'] == 591) & (df['capital_cntry'].isna()), 'capital_cntry'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read macro data from Excel file\n",
    "macro_df = pd.read_excel('macro_cntry.xlsx', header=0)\n",
    "\n",
    "# Sort by country and year\n",
    "macro_df.sort_values(by=['cntry', 'year'], inplace=True)\n",
    "\n",
    "# Group by country and assign a unique number to each group\n",
    "macro_df['ke'] = macro_df.groupby('cntry').cumcount() + 1\n",
    "\n",
    "# Keep only the first row for each country\n",
    "macro_df = macro_df[macro_df['ke'] == 1]\n",
    "\n",
    "# Rename columns\n",
    "macro_df.rename(columns={'GDP_percap': 'GDP_ti', 'Inflation': 'Inf_ti', \n",
    "                         'Dev_Assistance': 'Dev_ti', 'gini': 'gini_ti'}, inplace=True)\n",
    "\n",
    "# Drop the 'ke' column\n",
    "macro_df.drop(columns=['ke'], inplace=True)\n",
    "\n",
    "# Define the list of macro variables\n",
    "macro_vars = ['GDP_ti', 'Inf_ti', 'Dev_ti', 'gini_ti']\n",
    "\n",
    "# Iterate over macro variables\n",
    "for j in macro_vars:\n",
    "    # Calculate quartiles\n",
    "    macro_df[f'above_{j}'] = pd.qcut(macro_df[j], q=4, labels=False)\n",
    "    # Create a binary variable\n",
    "    macro_df[f'{j}b'] = 0\n",
    "    macro_df.loc[macro_df[f'above_{j}'] <= 3, f'{j}b'] = 0\n",
    "    macro_df.loc[macro_df[f'above_{j}'] == 4, f'{j}b'] = 1\n",
    "\n",
    "# Reorder columns\n",
    "macro_df = macro_df[['cntry'] + [f'{var}b' for var in macro_vars]]\n",
    "\n",
    "# Save the macro data\n",
    "macro_df.to_stata('macro_cntry_b.dta', write_index=False)\n",
    "\n",
    "# Read the main dataset\n",
    "main_df = pd.read_stata('pause_4_drought_win6.dta')\n",
    "\n",
    "# Sort by country and year\n",
    "main_df.sort_values(by=['cntry', 'year'], inplace=True)\n",
    "\n",
    "# Merge the main dataset with the macro data\n",
    "merged_df = pd.merge(main_df, macro_df, on='cntry', how='inner', validate='many_to_one')\n",
    "\n",
    "# Keep only the matched rows\n",
    "merged_df.dropna(subset=macro_vars, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(columns=['_merge'] + [f'{var}b' for var in macro_vars] + ['Rem_ti', 'Rem_tib'], inplace=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_stata('pause_5_drought_win6_merged.dta', write_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_stata('pause_5_1216_t.dta')\n",
    "\n",
    "# Create three-way interaction terms\n",
    "df['int_wav_coh_1525'] = df['aff_area'] * df['wave'] * df['aff_cohort_15_25']\n",
    "df['int_wav_coh_2635'] = df['aff_area'] * df['wave'] * df['aff_cohort_26_35']\n",
    "df['int_wav_coh_3645'] = df['aff_area'] * df['wave'] * df['aff_cohort_36_45']\n",
    "df['int_wav_coh_4655'] = df['aff_area'] * df['wave'] * df['aff_cohort_46_55']\n",
    "\n",
    "# Create two-way interaction terms\n",
    "df['int_wav'] = df['aff_area'] * df['wave']\n",
    "df['int_coh_1525'] = df['aff_area'] * df['aff_cohort_15_25']\n",
    "df['int_coh_2635'] = df['aff_area'] * df['aff_cohort_26_35']\n",
    "df['int_coh_3645'] = df['aff_area'] * df['aff_cohort_36_45']\n",
    "df['int_coh_4655'] = df['aff_area'] * df['aff_cohort_46_55']\n",
    "df['wav_coh_1525'] = df['wave'] * df['aff_cohort_15_25']\n",
    "df['wav_coh_2635'] = df['wave'] * df['aff_cohort_26_35']\n",
    "df['wav_coh_3645'] = df['wave'] * df['aff_cohort_36_45']\n",
    "df['wav_coh_4655'] = df['wave'] * df['aff_cohort_46_55']\n",
    "\n",
    "# Save the dataset\n",
    "df.to_stata('pause_5_1216_t.dta', write_index=False)\n",
    "\n",
    "# Load the second dataset\n",
    "df2 = pd.read_stata('z_withmex.dta')\n",
    "\n",
    "# Rename the 'dist' column to 'geolev1'\n",
    "df2.rename(columns={'dist': 'geolev1'}, inplace=True)\n",
    "\n",
    "# Replace values in 'geolev1' column to match with the first dataset\n",
    "df2['geolev1'].replace({591007: 591008, 591006: 591007, 591005: 591006, 591004: 591005,\n",
    "                        591003: 591004, 591002: 591003, 591001: 591002}, inplace=True)\n",
    "\n",
    "# Sort the dataframe by 'geolev1'\n",
    "df2.sort_values(by='geolev1', inplace=True)\n",
    "\n",
    "# Keep only specific rows based on country and year\n",
    "df2 = df2[(df2['country'] == 188) & (df2['year'] == 2010) |\n",
    "          (df2['country'] == 214) & (df2['year'] == 2010) |\n",
    "          (df2['country'] == 222) & (df2['year'] == 2007) |\n",
    "          (df2['country'] == 332) & (df2['year'] == 2003) |\n",
    "          (df2['country'] == 388) & (df2['year'] == 2001) |\n",
    "          (df2['country'] == 484) & (df2['year'] == 2010) |\n",
    "          (df2['country'] == 558) & (df2['year'] == 2005) |\n",
    "          (df2['country'] == 591) & (df2['year'] == 2010)]\n",
    "\n",
    "# Save the modified dataset\n",
    "df2.to_stata('z_readytomerge.dta', write_index=False)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset pause_5_1216_t\n",
    "pause_df = pd.read_stata('pause_5_1216_t.dta')\n",
    "\n",
    "# Sort by geolev1\n",
    "pause_df.sort_values(by='geolev1', inplace=True)\n",
    "\n",
    "# Drop the _merge column if it exists\n",
    "pause_df.drop(columns='_merge', errors='ignore', inplace=True)\n",
    "\n",
    "# Merge with z_readytomerge\n",
    "z_ready_df = pd.read_stata('z_readytomerge.dta')\n",
    "merged_df = pd.merge(pause_df, z_ready_df, on='geolev1', how='inner', validate='many_to_one')\n",
    "merged_df = merged_df[merged_df['_merge'] == 3]\n",
    "\n",
    "# Define a list of values for iteration\n",
    "values = [\"99\", \"95\", \"90\"]\n",
    "\n",
    "# Define a list of variables for interaction terms\n",
    "interaction_vars = ['wave', 'aff_cohort_15_25', 'aff_cohort_26_35', 'aff_cohort_36_45', 'aff_cohort_46_55']\n",
    "\n",
    "# Iterate over values and generate interaction terms\n",
    "for i in values:\n",
    "    for var in interaction_vars:\n",
    "        merged_df[f'z{i}_{var}'] = merged_df[f'z_{i}'] * merged_df[var]\n",
    "        merged_df[f'z{i}2_{var}'] = merged_df[f'z_{i}'] ** 2 * merged_df[var]\n",
    "\n",
    "# Save the dataset\n",
    "merged_df.to_stata('aerpp_ready_withmex.dta', write_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel files for Costa Rica and El Salvador\n",
    "costa_rica_df = pd.read_excel(\"GRP predictions_Costa Rica.xlsx\", sheet_name=\"admin1\", header=0)\n",
    "el_salvador_df = pd.read_excel(\"GRP predictions_El Salvador.xlsx\", sheet_name=\"admin1\", header=0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "costa_rica_df.drop(columns=[\"Official GDP1\", \"GDP2\", \"GDP3\", \"GDP4\", \"GDP5\", \"GDP6\"], inplace=True)\n",
    "el_salvador_df.drop(columns=[\"Official GDP1\", \"GDP2\", \"GDP3\", \"GDP4\", \"GDP5\", \"GDP6\"], inplace=True)\n",
    "\n",
    "# Define mapping for Costa Rica\n",
    "costa_rica_mapping = {\n",
    "    \"San Jose\": 188001,\n",
    "    \"Alajuela\": 188002,\n",
    "    \"Cartago\": 188003,\n",
    "    \"Heredia\": 188004,\n",
    "    \"Guanacaste\": 188005,\n",
    "    \"Puntarenas\": 188006,\n",
    "    \"Limon\": 188007\n",
    "}\n",
    "\n",
    "# Define mapping for El Salvador\n",
    "el_salvador_mapping = {\n",
    "    \"Ahuachapan\": 222001,\n",
    "    \"Santa Ana\": 222002,\n",
    "    \"Sonsonate\": 222003,\n",
    "    \"Chalatenango\": 222004,\n",
    "    \"La Libertad\": 222005,\n",
    "    \"San Salvador\": 222006,\n",
    "    \"Cuscatlan\": 222007,\n",
    "    \"La Paz\": 222008,\n",
    "    \"Cabanas\": 222009,\n",
    "    \"San Vicente\": 222010,\n",
    "    \"Usulutan\": 222011,\n",
    "    \"San Miguel\": 222012,\n",
    "    \"Morazan\": 222013,\n",
    "    \"La Union\": 222014\n",
    "}\n",
    "\n",
    "# Apply the mappings to create the 'dist' column\n",
    "costa_rica_df['dist'] = costa_rica_df['sub_level_name'].map(costa_rica_mapping)\n",
    "el_salvador_df['dist'] = el_salvador_df['sub_level_name'].map(el_salvador_mapping)\n",
    "\n",
    "# Save the modified DataFrames\n",
    "costa_rica_df.to_excel(\"gdp_temp_cos.xlsx\", index=False)\n",
    "el_salvador_df.to_excel(\"gdp_temp_sv.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file for Nicaragua\n",
    "nicaragua_df = pd.read_excel(\"GRP predictions_Nicaragua.xlsx\", sheet_name=\"admin1\", header=0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "nicaragua_df.drop(columns=[\"Official GDP1\", \"GDP2\", \"GDP3\", \"GDP4\", \"GDP5\", \"GDP6\"], inplace=True)\n",
    "\n",
    "# Define mapping for Nicaragua\n",
    "nicaragua_mapping = {\n",
    "    \"Nueva Segovia\": 558005,\n",
    "    \"Jinotega\": 558010,\n",
    "    \"Madriz\": 558020,\n",
    "    \"Chinandega\": 558030,\n",
    "    \"Leon\": 558035,\n",
    "    \"Esteli\": 558035,\n",
    "    \"Matagalpa\": 558040,\n",
    "    \"Boaco\": 558050,\n",
    "    \"Managua\": 558055,\n",
    "    \"Masaya\": 558060,\n",
    "    \"Chontales\": 558065,\n",
    "    \"Granada\": 558070,\n",
    "    \"Carazo\": 558075,\n",
    "    \"Rivas\": 558080,\n",
    "    \"Rio San Juan\": 558085,\n",
    "    \"Atlantico Norte\": 558093,\n",
    "    \"Atlantico Sur\": 558093\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the 'dist' column\n",
    "nicaragua_df['dist'] = nicaragua_df['sub_level_name'].map(nicaragua_mapping)\n",
    "\n",
    "# Drop rows where 'dist' is NaN\n",
    "nicaragua_df.dropna(subset=['dist'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame\n",
    "nicaragua_df.to_excel(\"gdp_temp_nic.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file for Panama\n",
    "panama_df = pd.read_excel(\"GRP predictions_Panama.xlsx\", sheet_name=\"admin1\", header=0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "panama_df.drop(columns=[\"Official GDP1\", \"GDP2\", \"GDP3\", \"GDP4\", \"GDP5\", \"GDP6\"], inplace=True)\n",
    "\n",
    "# Define mapping for Panama\n",
    "panama_mapping = {\n",
    "    \"Cocle\": 591001,\n",
    "    \"Colon\": 591002,\n",
    "    \"Bocas de Toro\": 591003,\n",
    "    \"Chiriqui\": 591003,\n",
    "    \"Ngabe Bugle\": 591003,\n",
    "    \"Veraguas\": 591003,\n",
    "    \"Embera\": 591004,\n",
    "    \"Darien\": 591004,\n",
    "    \"Herrera\": 591005,\n",
    "    \"Los Santos\": 591006,\n",
    "    \"Panama\": 591007\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the 'dist' column\n",
    "panama_df['dist'] = panama_df['sub_level_name'].map(panama_mapping)\n",
    "\n",
    "# Drop rows where 'dist' is NaN\n",
    "panama_df.dropna(subset=['dist'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame\n",
    "panama_df.to_excel(\"gdp_temp_pan.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GDP data for Costa Rica\n",
    "gdp_temp_cos = pd.read_stata(\"gdp_temp_cos.dta\")\n",
    "\n",
    "# Load GDP data for El Salvador\n",
    "gdp_temp_sv = pd.read_stata(\"gdp_temp_sv.dta\")\n",
    "\n",
    "# Load GDP data for Nicaragua\n",
    "gdp_temp_nic = pd.read_stata(\"gdp_temp_nic.dta\")\n",
    "\n",
    "# Load GDP data for Panama\n",
    "gdp_temp_pan = pd.read_stata(\"gdp_temp_pan.dta\")\n",
    "\n",
    "# Append the GDP dataframes\n",
    "gdp_temp = pd.concat([gdp_temp_cos, gdp_temp_sv, gdp_temp_nic, gdp_temp_pan], ignore_index=True)\n",
    "\n",
    "# Sort the combined dataframe\n",
    "gdp_temp.sort_values(by=['dist', 'year'], inplace=True)\n",
    "\n",
    "# Save the combined dataframe\n",
    "gdp_temp.to_stata(\"gdp_temp.dta\", write_index=False)\n",
    "\n",
    "# Load the weather data\n",
    "merra_final_withmex = pd.read_stata(\"merra_final_withmex.dta\")\n",
    "\n",
    "# Filter data for specific countries and years\n",
    "merra_final_withmex = merra_final_withmex[merra_final_withmex['country'].isin([188, 222, 558, 591])]\n",
    "merra_final_withmex = merra_final_withmex[merra_final_withmex['year'].isin([2000, 2005, 2010])]\n",
    "\n",
    "# Calculate mean temperature by district and year\n",
    "merra_final_withmex['t_yearmean'] = merra_final_withmex.groupby(['dist', 'year'])['daily_temp'].transform('mean')\n",
    "\n",
    "# Resetting index to make it sequential\n",
    "merra_final_withmex.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge weather data with GDP data\n",
    "merged_data = pd.merge_asof(merra_final_withmex.sort_values('year'), gdp_temp.sort_values('year'), by='dist', on='year')\n",
    "\n",
    "# Keep only matched rows\n",
    "merged_data.dropna(subset=['GDP1predicted'], inplace=True)\n",
    "\n",
    "# Resetting index to make it sequential\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Adjusting district codes\n",
    "merged_data['dist'].replace({\n",
    "    5910010: 591001,\n",
    "    591008: 591007,\n",
    "    591007: 591005,\n",
    "    591006: 591004,\n",
    "    591004: 591003,\n",
    "    591003: 591002,\n",
    "    591002: 591001\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with additional data from 'z_withmex' and 'cruts_5_rain_aerpp_gdp' datasets\n",
    "# Code for merging additional datasets is not provided and would depend on their structure\n",
    "\n",
    "# Perform regression analysis\n",
    "# The regression analysis part involves multiple steps and is not directly translatable to Python code without more context,\n",
    "# such as the structure of the dataset and the specific regression models being used.\n",
    "\n",
    "# Save the final dataset\n",
    "merged_data.to_stata(\"final_dataset.dta\", write_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GDP data from WDI\n",
    "gdp_wdi = pd.read_excel(\"gdp_wdi.xls\", sheet_name=\"Sheet1\")\n",
    "\n",
    "# Convert GDP columns to numeric\n",
    "for i in range(1, 7):\n",
    "    gdp_wdi[f'GDP{i}'] = pd.to_numeric(gdp_wdi[f'GDP{i}'], errors='coerce')\n",
    "\n",
    "# Sort by country and year\n",
    "gdp_wdi.sort_values(by=['country', 'year'], inplace=True)\n",
    "\n",
    "# Save the processed GDP data\n",
    "gdp_wdi.to_stata(\"gdp_long_dependent.dta\", write_index=False)\n",
    "\n",
    "# Load data from z_withmex\n",
    "z_withmex = pd.read_stata(\"z_withmex.dta\")\n",
    "\n",
    "# Calculate mean values of z scores by country and year\n",
    "z_country_mean = z_withmex.groupby(['country', 'year']).agg({\n",
    "    'z_99': 'mean',\n",
    "    'z_95': 'mean',\n",
    "    'z_90': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Save the aggregated z scores by country and year\n",
    "z_country_mean.to_stata(\"z_withmex_cntry.dta\", write_index=False)\n",
    "\n",
    "# Load data from cruts_5_rain_aerpp_gdp_long\n",
    "cruts_5_rain_aerpp_gdp_long = pd.read_stata(\"cruts_5_rain_aerpp_gdp_long.dta\")\n",
    "\n",
    "# Calculate mean values of 5-year rainfall by country and year\n",
    "rain_5yr_country_mean = cruts_5_rain_aerpp_gdp_long.groupby(['country', 'year'])['rain_5yr'].mean().reset_index()\n",
    "\n",
    "# Save the aggregated 5-year rainfall by country and year\n",
    "rain_5yr_country_mean.to_stata(\"cruts_5_rain_aerpp_gdp_cntry.dta\", write_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GDP data\n",
    "gdp_long_dependent = pd.read_stata(\"gdp_long_dependent.dta\")\n",
    "\n",
    "# Load z scores data aggregated by country and year\n",
    "z_withmex_cntry = pd.read_stata(\"z_withmex_cntry.dta\")\n",
    "\n",
    "# Merge GDP data with z scores data\n",
    "gdp_merged = pd.merge(gdp_long_dependent, z_withmex_cntry, on=['country', 'year'], how='inner')\n",
    "\n",
    "# Load 5-year rainfall data aggregated by country and year\n",
    "cruts_5_rain_aerpp_gdp_cntry = pd.read_stata(\"cruts_5_rain_aerpp_gdp_cntry.dta\")\n",
    "\n",
    "# Merge GDP data with 5-year rainfall data\n",
    "gdp_merged = pd.merge(gdp_merged, cruts_5_rain_aerpp_gdp_cntry, on=['country', 'year'], how='inner')\n",
    "\n",
    "# Convert GDP columns to billions\n",
    "gdp_merged['GDP1'] /= 10**9\n",
    "gdp_merged['GDP2'] /= 10**9\n",
    "gdp_merged['GDP3'] /= 10**9\n",
    "gdp_merged['GDP6'] /= 10**9\n",
    "\n",
    "# Replace negative or zero values in z scores with 0\n",
    "gdp_merged['z_99_cntry'].clip(lower=0, inplace=True)\n",
    "gdp_merged['z_95_cntry'].clip(lower=0, inplace=True)\n",
    "gdp_merged['z_90_cntry'].clip(lower=0, inplace=True)\n",
    "\n",
    "# Calculate squared values of 5-year rainfall\n",
    "gdp_merged['rain_5yr_cntry2'] = gdp_merged['rain_5yr_cntry'] ** 2\n",
    "\n",
    "# Generate dummy variables for countries\n",
    "gdp_merged = pd.get_dummies(gdp_merged, columns=['country'], prefix='cntry')\n",
    "\n",
    "# Generate interaction terms of country and year\n",
    "for i in range(1, 5):\n",
    "    gdp_merged[f'cntry_year{i}'] = gdp_merged[f'cntry_{i}'] * gdp_merged['year']\n",
    "\n",
    "# Calculate log GDP\n",
    "gdp_merged['loggdp6'] = np.log(gdp_merged['GDP6'])\n",
    "\n",
    "# Perform regression\n",
    "from linearmodels.panel import PanelOLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "varlist = ['loggdp6']\n",
    "zlist = ['z_90_cntry']\n",
    "\n",
    "for var in varlist:\n",
    "    for z in zlist:\n",
    "        exog_vars = [z, 'rain_5yr_cntry', 'rain_5yr_cntry2', 'country', 'year']\n",
    "        mod = PanelOLS.from_formula(f\"{var} ~ {z} + rain_5yr_cntry + rain_5yr_cntry2 + country + year\", data=gdp_merged)\n",
    "        res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "        res.summary().to_excel(\"gdp_WDI_final_log.xls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "aerpp_ready_withmex = pd.read_stata(\"aerpp_ready_withmex.dta\")\n",
    "\n",
    "# Filter out data for country 484\n",
    "aerpp_ready_nomex = aerpp_ready_withmex[aerpp_ready_withmex['cntry'] != 484]\n",
    "\n",
    "# Define the variables\n",
    "variables = ['z_99', 'z_95', 'z_90', 'rolling_dist_99', 'rolling_dist_95', 'rolling_dist_90']\n",
    "\n",
    "# Create histograms and density plots\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(aerpp_ready_withmex[var], bins=20, alpha=0.5, label='With Mexico', density=True)\n",
    "    plt.hist(aerpp_ready_nomex[var], bins=20, alpha=0.5, label='Without Mexico', density=True)\n",
    "    plt.title(f'Histogram and Density Plot for {var}')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'hist_density_{var}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_stata(\"your_dataset.dta\")\n",
    "\n",
    "# Define the variables\n",
    "variables = ['z_99', 'z_95', 'z_90', 'rolling_dist_99', 'rolling_dist_95', 'rolling_dist_90']\n",
    "\n",
    "# Polynomial regression function\n",
    "def poly_regression(x, y, degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(x.reshape(-1, 1))\n",
    "    poly.fit(X_poly, y)\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_poly, y)\n",
    "    return lin_reg.predict(X_poly)\n",
    "\n",
    "# Create polynomial regression plots\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(data[var], data['migrate'], color='blue', label='Actual Data')\n",
    "    plt.plot(np.sort(data[var]), poly_regression(data[var], data['migrate'], 3)[np.argsort(data[var])], color='red', label='Polynomial Regression (Degree 3)')\n",
    "    plt.title(f'Intensity vs. Migrate for {var}')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Migrate')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'lpoly_{var}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data = pd.read_stata(\"aerpp_ready_withmex.dta\")\n",
    "\n",
    "# Filter the data to remove rows where z_90 <= 0\n",
    "data_filtered = data[data['z_90'] > 0]\n",
    "\n",
    "# Set the style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the density plot for z_90\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_filtered['z_90'], shade=True, color=\"b\", label=\"z_90 Density Plot\")\n",
    "plt.axvline(x=0.80, linestyle='--', color='r', label='PCI 80%')\n",
    "plt.axvline(x=1.64, linestyle='--', color='g', label='PCI 90%')\n",
    "plt.xlabel(\"z_90\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot for Standardized Intensity (z_90)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"density_plot_z90.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data into pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Define the core variables and micro control variables\n",
    "core_vars = [\"int99_0_wav_coh_1525\", \"int99_0_wav_coh_2635\", \"int99_0_wav_coh_3645\", \"int99_0_wav_coh_4655\",\n",
    "             \"int99_0_wav\", \"int99_0_coh_1525\", \"int99_0_coh_2635\", \"int99_0_coh_3645\", \"int99_0_coh_4655\",\n",
    "             \"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"int99_0\", \"wave\", \"aff_cohort\"]\n",
    "\n",
    "micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for core_var in core_vars:\n",
    "    for micro_control_var in micro_control_vars:\n",
    "        # Filter the data if necessary (exclude country 388)\n",
    "        filtered_data = data[data['cntry'] != 388]\n",
    "        \n",
    "        # Define the independent variables\n",
    "        X = filtered_data[[core_var] + micro_control_vars]\n",
    "        \n",
    "        # Add constant to the independent variables\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Define the dependent variable\n",
    "        y = filtered_data['migrate']\n",
    "        \n",
    "        # Fit the OLS regression model\n",
    "        model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "        \n",
    "        # Print the regression summary\n",
    "        print(model.summary())\n",
    "        \n",
    "        # Save the regression results\n",
    "        with open(\"regression_results.txt\", \"a\") as f:\n",
    "            f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Define the core variables and micro control variables\n",
    "core_vars = [\"int99_0_wav_coh_1525\", \"int99_0_wav_coh_2635\", \"int99_0_wav_coh_3645\", \"int99_0_wav_coh_4655\",\n",
    "             \"int99_0_wav\", \"int99_0_coh_1525\", \"int99_0_coh_2635\", \"int99_0_coh_3645\", \"int99_0_coh_4655\",\n",
    "             \"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"int99_0\", \"wave\", \"aff_cohort\"]\n",
    "\n",
    "micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for core_var in core_vars:\n",
    "    for micro_control_var in micro_control_vars:\n",
    "        # Filter the data if necessary (exclude country 388 and select only males)\n",
    "        filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 1)]\n",
    "        \n",
    "        # Define the independent variables\n",
    "        X = filtered_data[[core_var] + micro_control_vars]\n",
    "        \n",
    "        # Add a constant to the independent variables\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Define the dependent variable\n",
    "        y = filtered_data['migrate']\n",
    "        \n",
    "        # Fit the OLS regression model\n",
    "        model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "        \n",
    "        # Print the regression summary\n",
    "        print(model.summary())\n",
    "        \n",
    "        # Save the regression results\n",
    "        with open(\"1st_set_male.xls\", \"a\") as f:\n",
    "            f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Define the core variables and micro control variables\n",
    "core_vars = [\"int99_0_wav_coh_1525\", \"int99_0_wav_coh_2635\", \"int99_0_wav_coh_3645\", \"int99_0_wav_coh_4655\",\n",
    "             \"int99_0_wav\", \"int99_0_coh_1525\", \"int99_0_coh_2635\", \"int99_0_coh_3645\", \"int99_0_coh_4655\",\n",
    "             \"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"int99_0\", \"wave\", \"aff_cohort\"]\n",
    "\n",
    "micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for core_var in core_vars:\n",
    "    for micro_control_var in micro_control_vars:\n",
    "        # Filter the data if necessary (exclude country 388 and select only females)\n",
    "        filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 0)]\n",
    "        \n",
    "        # Define the independent variables\n",
    "        X = filtered_data[[core_var] + micro_control_vars]\n",
    "        \n",
    "        # Add a constant to the independent variables\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Define the dependent variable\n",
    "        y = filtered_data['migrate']\n",
    "        \n",
    "        # Fit the OLS regression model\n",
    "        model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "        \n",
    "        # Print the regression summary\n",
    "        print(model.summary())\n",
    "        \n",
    "        # Save the regression results\n",
    "        with open(\"1st_set_female.xls\", \"a\") as f:\n",
    "            f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_vars = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                     \"int{}_{}_wav\".format(i, j),\n",
    "                     \"int{}_{}_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_coh_4655\".format(i, j),\n",
    "                     \"wav_coh_1525\",\n",
    "                     \"wav_coh_2635\",\n",
    "                     \"wav_coh_3645\",\n",
    "                     \"wav_coh_4655\",\n",
    "                     \"int{}_{}\".format(i, j),\n",
    "                     \"wave\",\n",
    "                     \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for core_var in core_vars:\n",
    "            for micro_control_var in micro_control_vars:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['primary_edu'] == 1)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[core_var] + [micro_control_var] + ['pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_pooled_skilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_vars = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                     \"int{}_{}_wav\".format(i, j),\n",
    "                     \"int{}_{}_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_coh_4655\".format(i, j),\n",
    "                     \"wav_coh_1525\",\n",
    "                     \"wav_coh_2635\",\n",
    "                     \"wav_coh_3645\",\n",
    "                     \"wav_coh_4655\",\n",
    "                     \"int{}_{}\".format(i, j),\n",
    "                     \"wave\",\n",
    "                     \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for core_var in core_vars:\n",
    "            for micro_control_var in micro_control_vars:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['primary_edu'] == 1)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[core_var] + [micro_control_var] + ['pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_pooled_skilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_vars = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                     \"int{}_{}_wav\".format(i, j),\n",
    "                     \"int{}_{}_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_coh_4655\".format(i, j),\n",
    "                     \"wav_coh_1525\",\n",
    "                     \"wav_coh_2635\",\n",
    "                     \"wav_coh_3645\",\n",
    "                     \"wav_coh_4655\",\n",
    "                     \"int{}_{}\".format(i, j),\n",
    "                     \"wave\",\n",
    "                     \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for core_var in core_vars:\n",
    "            for micro_control_var in micro_control_vars:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 1) & (data['primary_edu'] == 1)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[core_var] + [micro_control_var] + ['pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_male_skilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Iterate over each combination of core variables and micro control variables\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_vars = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                     \"int{}_{}_wav\".format(i, j),\n",
    "                     \"int{}_{}_coh_1525\".format(i, j),\n",
    "                     \"int{}_{}_coh_2635\".format(i, j),\n",
    "                     \"int{}_{}_coh_3645\".format(i, j),\n",
    "                     \"int{}_{}_coh_4655\".format(i, j),\n",
    "                     \"wav_coh_1525\",\n",
    "                     \"wav_coh_2635\",\n",
    "                     \"wav_coh_3645\",\n",
    "                     \"wav_coh_4655\",\n",
    "                     \"int{}_{}\".format(i, j),\n",
    "                     \"wave\",\n",
    "                     \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_vars = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for core_var in core_vars:\n",
    "            for micro_control_var in micro_control_vars:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 0) & (data['primary_edu'] == 1)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[core_var] + [micro_control_var] + ['pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_female_skilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data.dta\")\n",
    "\n",
    "# Iterate over each combination of i and j\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_var = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                    \"int{}_{}_wav\".format(i, j),\n",
    "                    \"int{}_{}_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_coh_4655\".format(i, j),\n",
    "                    \"wav_coh_1525\",\n",
    "                    \"wav_coh_2635\",\n",
    "                    \"wav_coh_3645\",\n",
    "                    \"wav_coh_4655\",\n",
    "                    \"int{}_{}\".format(i, j),\n",
    "                    \"wave\",\n",
    "                    \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_var = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for var in core_var:\n",
    "            for micro_var in micro_control_var:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['primary_edu'] == 0)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[var, micro_var, 'pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_pooled_unskilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data.dta\")\n",
    "\n",
    "# Iterate over each combination of i and j\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_var = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                    \"int{}_{}_wav\".format(i, j),\n",
    "                    \"int{}_{}_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_coh_4655\".format(i, j),\n",
    "                    \"wav_coh_1525\",\n",
    "                    \"wav_coh_2635\",\n",
    "                    \"wav_coh_3645\",\n",
    "                    \"wav_coh_4655\",\n",
    "                    \"int{}_{}\".format(i, j),\n",
    "                    \"wave\",\n",
    "                    \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_var = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for var in core_var:\n",
    "            for micro_var in micro_control_var:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 1) & (data['primary_edu'] == 0)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[var, micro_var, 'pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_male_unskilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data.dta\")\n",
    "\n",
    "# Iterate over each combination of i and j\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\"]:\n",
    "        core_var = [\"int{}_{}_wav_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_wav_coh_4655\".format(i, j),\n",
    "                    \"int{}_{}_wav\".format(i, j),\n",
    "                    \"int{}_{}_coh_1525\".format(i, j),\n",
    "                    \"int{}_{}_coh_2635\".format(i, j),\n",
    "                    \"int{}_{}_coh_3645\".format(i, j),\n",
    "                    \"int{}_{}_coh_4655\".format(i, j),\n",
    "                    \"wav_coh_1525\",\n",
    "                    \"wav_coh_2635\",\n",
    "                    \"wav_coh_3645\",\n",
    "                    \"wav_coh_4655\",\n",
    "                    \"int{}_{}\".format(i, j),\n",
    "                    \"wave\",\n",
    "                    \"aff_cohort_*\"]\n",
    "        \n",
    "        micro_control_var = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "        for var in core_var:\n",
    "            for micro_var in micro_control_var:\n",
    "                # Filter the data\n",
    "                filtered_data = data[(data['cntry'] != 388) & (data['sex'] == 0) & (data['primary_edu'] == 0)]\n",
    "\n",
    "                # Define the independent variables\n",
    "                X = filtered_data[[var, micro_var, 'pre_dist']]\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                # Define the dependent variable\n",
    "                y = filtered_data['migrate']\n",
    "\n",
    "                # Fit the OLS regression model\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['c2']})\n",
    "\n",
    "                # Print the regression summary\n",
    "                print(model.summary())\n",
    "\n",
    "                # Save the regression results\n",
    "                with open(\"1st_set_female_unskilled.xls\", \"a\") as f:\n",
    "                    f.write(str(model.summary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"aerpp_ready_withmex.dta\")\n",
    "\n",
    "# Generate new variables int99_0, int95_0, int90_0, int99_1, int95_1, int90_1\n",
    "data['int99_0'] = data['z_99']\n",
    "data.loc[data['z_99'] <= 0, 'int99_0'] = 0\n",
    "data['int95_0'] = data['z_95']\n",
    "data.loc[data['z_95'] <= 0, 'int95_0'] = 0\n",
    "data['int90_0'] = data['z_90']\n",
    "data.loc[data['z_90'] <= 0, 'int90_0'] = 0\n",
    "data['int99_1'] = data['z_99']\n",
    "data.loc[data['z_99'] <= 1, 'int99_1'] = 0\n",
    "data['int95_1'] = data['z_95']\n",
    "data.loc[data['z_95'] <= 1, 'int95_1'] = 0\n",
    "data['int90_1'] = data['z_90']\n",
    "data.loc[data['z_90'] <= 1, 'int90_1'] = 0\n",
    "\n",
    "# Iterate over each combination of i and j\n",
    "for i in [\"99\", \"95\", \"90\"]:\n",
    "    for j in [\"0\", \"1\"]:\n",
    "        # Generate three-way variables\n",
    "        data[f'int{i}_{j}_wav_coh_1525'] = data[f'int{i}_{j}'] * data['wave'] * data['aff_cohort_15_25']\n",
    "        data[f'int{i}_{j}_wav_coh_2635'] = data[f'int{i}_{j}'] * data['wave'] * data['aff_cohort_26_35']\n",
    "        data[f'int{i}_{j}_wav_coh_3645'] = data[f'int{i}_{j}'] * data['wave'] * data['aff_cohort_36_45']\n",
    "        data[f'int{i}_{j}_wav_coh_4655'] = data[f'int{i}_{j}'] * data['wave'] * data['aff_cohort_46_55']\n",
    "        \n",
    "        # Generate two-way variables\n",
    "        data[f'int{i}_{j}_wav'] = data[f'int{i}_{j}'] * data['wave']\n",
    "        data[f'int{i}_{j}_coh_1525'] = data[f'int{i}_{j}'] * data['aff_cohort_15_25']\n",
    "        data[f'int{i}_{j}_coh_2635'] = data[f'int{i}_{j}'] * data['aff_cohort_26_35']\n",
    "        data[f'int{i}_{j}_coh_3645'] = data[f'int{i}_{j}'] * data['aff_cohort_36_45']\n",
    "        data[f'int{i}_{j}_coh_4655'] = data[f'int{i}_{j}'] * data['aff_cohort_46_55']\n",
    "\n",
    "# Generate to_capital, to_noncapital, to_capital_cntry, and to_noncapital_cntry variables\n",
    "data['to_capital'] = 0\n",
    "data.loc[(data['migrate'] == 1) & (data['capital'] == 1), 'to_capital'] = 1\n",
    "\n",
    "data['to_noncapital'] = 0\n",
    "data.loc[(data['migrate'] == 1) & (data['capital'] == 0), 'to_noncapital'] = 1\n",
    "\n",
    "data['to_capital_cntry'] = 0\n",
    "data.loc[(data['migrate'] == 1) & (data['capital_cntry'] == 1), 'to_capital_cntry'] = 1\n",
    "\n",
    "data['to_noncapital_cntry'] = 0\n",
    "data.loc[(data['migrate'] == 1) & (data['capital_cntry'] == 0), 'to_noncapital_cntry'] = 1\n",
    "\n",
    "# Save the modified DataFrame to a new Stata file\n",
    "data.to_stata(\"modified_data.dta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data_file.dta\")\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = pd.DataFrame(index=[\"Mean Migration Rate\", \"Mean to Capital Country\", \"Mean to Capital\", \"Mean Migration Rate (Female)\", \n",
    "                               \"Mean to Capital Country (Female)\", \"Mean to Capital (Female)\"],\n",
    "                       columns=[\"Female\", \"Male\"])\n",
    "\n",
    "# Calculate mean values for different groups\n",
    "female_data = data[data['sex'] == 0]  # Filter female data\n",
    "male_data = data[data['sex'] == 1]    # Filter male data\n",
    "\n",
    "# Mean migration rates and temperature values for females\n",
    "results.loc[\"Mean Migration Rate\", \"Female\"] = female_data['int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country\", \"Female\"] = female_data.loc[female_data['to_capital_cntry'].notnull(), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital\", \"Female\"] = female_data.loc[female_data['to_capital'].notnull(), 'int90_0'].mean()\n",
    "\n",
    "# Mean migration rates and temperature values for males\n",
    "results.loc[\"Mean Migration Rate\", \"Male\"] = male_data['int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country\", \"Male\"] = male_data.loc[male_data['to_capital_cntry'].notnull(), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital\", \"Male\"] = male_data.loc[male_data['to_capital'].notnull(), 'int90_0'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data_file.dta\")\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = pd.DataFrame(index=[\"Mean Migration Rate (Primary Education)\", \"Mean to Capital Country (Primary Education)\", \"Mean to Capital (Primary Education)\",\n",
    "                               \"Mean Migration Rate (Non-Primary Education)\", \"Mean to Capital Country (Non-Primary Education)\", \"Mean to Capital (Non-Primary Education)\"],\n",
    "                       columns=[\"Female\", \"Male\"])\n",
    "\n",
    "# Calculate mean values for different groups\n",
    "female_data = data[data['sex'] == 0]  # Filter female data\n",
    "male_data = data[data['sex'] == 1]    # Filter male data\n",
    "\n",
    "# Mean migration rates and temperature values for females with primary education\n",
    "results.loc[\"Mean Migration Rate (Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] == 0) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country (Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] == 0) & (female_data['to_capital_cntry'].notnull()) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital (Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] == 0) & (female_data['to_capital'].notnull()) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "\n",
    "# Mean migration rates and temperature values for males with primary education\n",
    "results.loc[\"Mean Migration Rate (Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] == 0) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country (Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] == 0) & (male_data['to_capital_cntry'].notnull()) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital (Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] == 0) & (male_data['to_capital'].notnull()) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "\n",
    "# Mean migration rates and temperature values for females with non-primary education\n",
    "results.loc[\"Mean Migration Rate (Non-Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] != 0) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country (Non-Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] != 0) & (female_data['to_capital_cntry'].notnull()) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital (Non-Primary Education)\", \"Female\"] = female_data.loc[(female_data['primary_edu'] != 0) & (female_data['to_capital'].notnull()) & (female_data['cntry'] != 388), 'int90_0'].mean()\n",
    "\n",
    "# Mean migration rates and temperature values for males with non-primary education\n",
    "results.loc[\"Mean Migration Rate (Non-Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] != 0) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital Country (Non-Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] != 0) & (male_data['to_capital_cntry'].notnull()) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "results.loc[\"Mean to Capital (Non-Primary Education)\", \"Male\"] = male_data.loc[(male_data['primary_edu'] != 0) & (male_data['to_capital'].notnull()) & (male_data['cntry'] != 388), 'int90_0'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data_file.dta\")\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_primary_edu = pd.DataFrame(index=[\"Mean Migration Rate (Primary Education)\", \"Mean to Capital Country (Primary Education)\", \"Mean to Capital (Primary Education)\"],\n",
    "                                   columns=[\"Female\", \"Male\"])\n",
    "\n",
    "# Calculate mean values for different groups with primary education\n",
    "female_data_primary_edu = data[(data['sex'] == 0) & (data['primary_edu'] == 1) & (data['cntry'] != 388)]  # Filter female data with primary education\n",
    "male_data_primary_edu = data[(data['sex'] == 1) & (data['primary_edu'] == 1) & (data['cntry'] != 388)]    # Filter male data with primary education\n",
    "\n",
    "# Mean migration rates and temperature values for females with primary education\n",
    "results_primary_edu.loc[\"Mean Migration Rate (Primary Education)\", \"Female\"] = female_data_primary_edu.loc[~female_data_primary_edu['int90_0'].isnull(), 'int90_0'].mean()\n",
    "results_primary_edu.loc[\"Mean to Capital Country (Primary Education)\", \"Female\"] = female_data_primary_edu.loc[~female_data_primary_edu['to_capital_cntry'].isnull(), 'int90_0'].mean()\n",
    "results_primary_edu.loc[\"Mean to Capital (Primary Education)\", \"Female\"] = female_data_primary_edu.loc[~female_data_primary_edu['to_capital'].isnull(), 'int90_0'].mean()\n",
    "\n",
    "# Mean migration rates and temperature values for males with primary education\n",
    "results_primary_edu.loc[\"Mean Migration Rate (Primary Education)\", \"Male\"] = male_data_primary_edu.loc[~male_data_primary_edu['int90_0'].isnull(), 'int90_0'].mean()\n",
    "results_primary_edu.loc[\"Mean to Capital Country (Primary Education)\", \"Male\"] = male_data_primary_edu.loc[~male_data_primary_edu['to_capital_cntry'].isnull(), 'int90_0'].mean()\n",
    "results_primary_edu.loc[\"Mean to Capital (Primary Education)\", \"Male\"] = male_data_primary_edu.loc[~male_data_primary_edu['to_capital'].isnull(), 'int90_0'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(results_primary_edu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data_file.dta\")\n",
    "\n",
    "# Filter the data for males only and excluding country 388\n",
    "male_data = data[(data['sex'] == 1) & (data['cntry'] != 388)]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_male = pd.DataFrame(columns=[\"Mean\", \"Standard Deviation\"])\n",
    "\n",
    "# Calculate summary statistics for each variable\n",
    "variables = [\"urban\", \"migrate\", \"wave\", \"aff_cohort_15_25\", \"aff_cohort_26_35\", \"aff_cohort_36_45\",\n",
    "             \"aff_cohort_46_55\", \"aff_cohort_56_65\", \"cruts_5avg\", \"primary_edu\", \"to_capital\", \"to_capital_cntry\",\n",
    "             \"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"int90_0\", \"int90_0_wav_coh_1525\",\n",
    "             \"int90_0_wav_coh_2635\", \"int90_0_wav_coh_3645\", \"int90_0_wav_coh_4655\", \"int90_0_wav\",\n",
    "             \"int90_0_coh_1525\", \"int90_0_coh_2635\", \"int90_0_coh_3645\", \"int90_0_coh_4655\"]\n",
    "\n",
    "for variable in variables:\n",
    "    mean = male_data[variable].mean()\n",
    "    std_dev = male_data[variable].std()\n",
    "    results_male.loc[variable] = [mean, std_dev]\n",
    "\n",
    "# Print the results\n",
    "print(results_male)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"your_data_file.dta\")\n",
    "\n",
    "# Filter the data for females only and excluding country 388\n",
    "female_data = data[(data['sex'] == 0) & (data['cntry'] != 388)]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_female = pd.DataFrame(columns=[\"Mean\", \"Standard Deviation\"])\n",
    "\n",
    "# Calculate summary statistics for each variable\n",
    "variables = [\"urban\", \"migrate\", \"wave\", \"aff_cohort_15_25\", \"aff_cohort_26_35\", \"aff_cohort_36_45\",\n",
    "             \"aff_cohort_46_55\", \"aff_cohort_56_65\", \"cruts_5avg\", \"primary_edu\", \"to_capital\", \"to_capital_cntry\",\n",
    "             \"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"int90_0\", \"int90_0_wav_coh_1525\",\n",
    "             \"int90_0_wav_coh_2635\", \"int90_0_wav_coh_3645\", \"int90_0_wav_coh_4655\", \"int90_0_wav\",\n",
    "             \"int90_0_coh_1525\", \"int90_0_coh_2635\", \"int90_0_coh_3645\", \"int90_0_coh_4655\"]\n",
    "\n",
    "for variable in variables:\n",
    "    mean = female_data[variable].mean()\n",
    "    std_dev = female_data[variable].std()\n",
    "    results_female.loc[variable] = [mean, std_dev]\n",
    "\n",
    "# Print the results\n",
    "print(results_female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"aerpp_ready_withmex.dta\")\n",
    "\n",
    "# Define the core and micro control variables\n",
    "corevar = [\"wav_coh_1525\", \"wav_coh_2635\", \"wav_coh_3645\", \"wav_coh_4655\", \"wave\"]\n",
    "microcvar = [\"sex\", \"primary_edu\", \"cruts_5avg\", \"cruts_5avg_sq\"]\n",
    "\n",
    "# Filter data for males\n",
    "male_data = data[(data['sex'] == 1) & (data['cntry'] != 388)]\n",
    "\n",
    "# Run regression for males\n",
    "X_male = sm.add_constant(male_data[corevar + microcvar])\n",
    "y_male = male_data['migrate']\n",
    "model_male = sm.WLS(y_male, X_male, weights=male_data['perwt']).fit(cov_type='cluster', cov_kwds={'groups': male_data['c2']})\n",
    "\n",
    "# Print regression results for males\n",
    "print(model_male.summary())\n",
    "\n",
    "# Save regression results for males to Excel\n",
    "model_male_results = model_male.get_robustcov_results()\n",
    "model_male_results.summary().tables[1].to_excel(\"doublediff_final.xls\", startrow=0, startcol=0)\n",
    "\n",
    "# Filter data for females\n",
    "female_data = data[(data['sex'] == 0) & (data['cntry'] != 388)]\n",
    "\n",
    "# Run regression for females\n",
    "X_female = sm.add_constant(female_data[corevar + microcvar])\n",
    "y_female = female_data['migrate']\n",
    "model_female = sm.WLS(y_female, X_female, weights=female_data['perwt']).fit(cov_type='cluster', cov_kwds={'groups': female_data['c2']})\n",
    "\n",
    "# Print regression results for females\n",
    "print(model_female.summary())\n",
    "\n",
    "# Save regression results for females to Excel\n",
    "model_female_results = model_female.get_robustcov_results()\n",
    "model_female_results.summary().tables[1].to_excel(\"doublediff_final.xls\", startrow=model_male_results.summary().tables[1].shape[0]+2, startcol=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a pandas DataFrame\n",
    "data = pd.read_stata(\"aerpp_ready_withmex.dta\")\n",
    "\n",
    "# Generate variables for affdist, aff_cohort_general, and coh_affdist\n",
    "data['affdist'] = (data['int90_0'] > 0).astype(int)\n",
    "data['aff_cohort_general'] = ((data['aff_cohort_56_65'] == 1) | (data['aff_cohort_46_55'] == 1) | (data['aff_cohort_36_45'] == 1)).astype(int)\n",
    "data['coh_affdist'] = data['affdist'] * data['aff_cohort_general']\n",
    "\n",
    "# Filter data for males and females separately\n",
    "male_data = data[(data['sex'] == 1) & (data['cntry'] != 388)]\n",
    "female_data = data[(data['sex'] == 0) & (data['cntry'] != 388)]\n",
    "\n",
    "# Define a function to perform balancing tests\n",
    "def perform_balancing_tests(data, gender):\n",
    "    results = {}\n",
    "\n",
    "    # Perform balancing tests\n",
    "    results['migrate_mean'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['migrate'].mean()\n",
    "    results['migrate_count'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['migrate'].count()\n",
    "    results['sex_mean'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['sex'].mean()\n",
    "    results['sex_count'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['sex'].count()\n",
    "    results['primary_edu_mean'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['primary_edu'].mean()\n",
    "    results['primary_edu_count'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['primary_edu'].count()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Perform balancing tests for males\n",
    "male_balancing_results = perform_balancing_tests(male_data, 'Male')\n",
    "\n",
    "# Perform balancing tests for females\n",
    "female_balancing_results = perform_balancing_tests(female_data, 'Female')\n",
    "\n",
    "# Print or save the results as needed\n",
    "print(\"Male Balancing Results:\")\n",
    "print(male_balancing_results)\n",
    "\n",
    "print(\"\\nFemale Balancing Results:\")\n",
    "print(female_balancing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform additional balancing tests for cruts_5avg\n",
    "def perform_cruts_5avg_balancing_tests(data, gender):\n",
    "    results = {}\n",
    "\n",
    "    # Perform balancing tests for cruts_5avg\n",
    "    results['cruts_5avg_mean'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['cruts_5avg'].mean()\n",
    "    results['cruts_5avg_count'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['cruts_5avg'].count()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Perform additional balancing tests for males for cruts_5avg\n",
    "male_cruts_5avg_balancing_results = perform_cruts_5avg_balancing_tests(male_data, 'Male')\n",
    "\n",
    "# Perform additional balancing tests for females for cruts_5avg\n",
    "female_cruts_5avg_balancing_results = perform_cruts_5avg_balancing_tests(female_data, 'Female')\n",
    "\n",
    "# Print or save the results as needed\n",
    "print(\"Male Balancing Results for cruts_5avg:\")\n",
    "print(male_cruts_5avg_balancing_results)\n",
    "\n",
    "print(\"\\nFemale Balancing Results for cruts_5avg:\")\n",
    "print(female_cruts_5avg_balancing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform balancing tests for cruts_5avg by gender\n",
    "def perform_cruts_5avg_balancing_tests_by_gender(data, gender):\n",
    "    results = {}\n",
    "\n",
    "    # Perform balancing tests for cruts_5avg for the specified gender\n",
    "    results[f'{gender}_cruts_5avg_mean'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['cruts_5avg'].mean()\n",
    "    results[f'{gender}_cruts_5avg_count'] = data.groupby(['wave', 'affdist', 'aff_cohort_general'])['cruts_5avg'].count()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Perform balancing tests for cruts_5avg for females\n",
    "female_cruts_5avg_balancing_results = perform_cruts_5avg_balancing_tests_by_gender(female_data, 'female')\n",
    "\n",
    "# Perform balancing tests for cruts_5avg for males\n",
    "male_cruts_5avg_balancing_results = perform_cruts_5avg_balancing_tests_by_gender(male_data, 'male')\n",
    "\n",
    "# Print or save the results as needed\n",
    "print(\"Female Balancing Results for cruts_5avg:\")\n",
    "print(female_cruts_5avg_balancing_results)\n",
    "\n",
    "print(\"\\nMale Balancing Results for cruts_5avg:\")\n",
    "print(male_cruts_5avg_balancing_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
